{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "EkqUJzghZqe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364faba3-f602-4c3c-c08c-13f1a6106f62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieves your external IP address using the wget command.\n",
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "LgdvWKkHbnEK",
        "outputId": "9511512e-e77d-4516-a24c-e76616a00b3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.16.197.182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install localtunnel@2.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41GIkyGtz-hh",
        "outputId": "64fd0329-8ed7-47eb-fda4-6b2820041a53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting localtunnel@ 2.0.2\n",
            "\u001b[31mERROR: Could not install packages due to an OSError: Invalid URL '2.0.2': No scheme supplied. Perhaps you meant https://2.0.2?\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper functions for data integration\n",
        "def load_mock_data(file_path):\n",
        "    \"\"\"\n",
        "    Load and normalize mock health data from a CSV file.\n",
        "    \"\"\"\n",
        "    # Load the data\n",
        "    mock_data = pd.read_csv(file_path)\n",
        "\n",
        "    # Normalize the data\n",
        "    mock_data['date'] = pd.to_datetime(mock_data['date'], format='%m/%d/%Y')\n",
        "\n",
        "    return mock_data\n",
        "\n",
        "def save_normalized_data(df, output_dir):\n",
        "    \"\"\"\n",
        "    Save normalized data to CSV and JSON.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    json_path = os.path.join(output_dir, \"processed_health_data.json\")\n",
        "    csv_path = os.path.join(output_dir, \"processed_health_data.csv\")\n",
        "\n",
        "    # Save JSON and CSV\n",
        "    df.to_json(json_path, orient=\"records\", lines=True)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "\n",
        "    return csv_path\n",
        "\n",
        "# Load and process the data\n",
        "mock_file_path = \"/content/MOCK_DATA.csv\"\n",
        "output_dir = \"/content/output\"\n",
        "mock_data = load_mock_data(mock_file_path)\n",
        "normalized_csv_path = save_normalized_data(mock_data, output_dir)\n",
        "\n",
        "# Streamlit starts here\n",
        "st.sidebar.title(\"Mind-Health App\")\n",
        "st.sidebar.markdown(\"AI-driven insights for health metrics. Powered by **mock data** and **AI models**.\")\n",
        "st.sidebar.markdown(\"---\")\n",
        "\n",
        "st.title(\"AI Health Insights Dashboard\")\n",
        "\n",
        "# Load health dataset\n",
        "@st.cache_data\n",
        "def load_health_data():\n",
        "    return pd.read_csv(normalized_csv_path)\n",
        "\n",
        "health_data = load_health_data()\n",
        "\n",
        "# Pre-calculate dataset averages for quick insights\n",
        "average_metrics = {\n",
        "    \"daily_steps\": np.mean(health_data[\"daily_steps\"]),\n",
        "    \"daily_calories_burned\": np.mean(health_data[\"daily_calories_burned\"]),\n",
        "    \"daily_active_minutes\": np.mean(health_data[\"daily_active_minutes\"]),\n",
        "    \"daily_weight_kg\": np.mean(health_data[\"daily_weight_kg\"]),\n",
        "    \"daily_sleep_hours\": np.mean(health_data[\"daily_sleep_hours\"]),\n",
        "}\n",
        "\n",
        "# Load AI models\n",
        "@st.cache_resource\n",
        "def load_text_generation_model():\n",
        "    return pipeline(\"text2text-generation\", model=\"facebook/blenderbot-400M-distill\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_sentiment_analysis_model():\n",
        "    return pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "text_generation_model = load_text_generation_model()\n",
        "sentiment_analysis_model = load_sentiment_analysis_model()\n",
        "\n",
        "# Tabs for different AI-driven functionalities\n",
        "tab1, tab2, tab3 = st.tabs([\"Fitness Tracker\", \"Sleep Analysis\", \"Journaling Sentiment Analysis\"])\n",
        "\n",
        "# Tab 1: Fitness Tracker\n",
        "with tab1:\n",
        "    st.subheader(\"Fitness Tracker\")\n",
        "    st.markdown(\"Enter your fitness data for actionable insights.\")\n",
        "\n",
        "    # Inputs\n",
        "    weight = st.number_input('Weight (kg):', min_value=1, step=1)\n",
        "    steps = st.number_input('Steps Today:', min_value=0, step=1)\n",
        "    calories = st.number_input('Calories Burned:', min_value=0, step=1)\n",
        "    active_minutes = st.number_input('Active Minutes:', min_value=0, step=1)\n",
        "\n",
        "    # Generate insights\n",
        "    if st.button(\"Get Fitness Insights\"):\n",
        "        input_text = (f\"User has {steps} steps, burned {calories} calories, \"\n",
        "                      f\"did {active_minutes} active minutes, and weighs {weight} kg. Provide a fitness tip.\")\n",
        "        with st.spinner(\"Generating insights...\"):\n",
        "            tip = text_generation_model(input_text)[0][\"generated_text\"]\n",
        "\n",
        "        # Visual comparison\n",
        "        user_data = [steps, calories, active_minutes]\n",
        "        avg_data = [\n",
        "            average_metrics[\"daily_steps\"],\n",
        "            average_metrics[\"daily_calories_burned\"],\n",
        "            average_metrics[\"daily_active_minutes\"]\n",
        "        ]\n",
        "        labels = [\"Steps\", \"Calories\", \"Active Minutes\"]\n",
        "\n",
        "        st.success(f\"Fitness Tip: {tip}\")\n",
        "        st.write(\"Your metrics vs. dataset averages:\")\n",
        "        plt.bar(labels, user_data, color=\"blue\", alpha=0.6, label=\"Your Data\")\n",
        "        plt.bar(labels, avg_data, color=\"green\", alpha=0.3, label=\"Average\")\n",
        "        plt.legend()\n",
        "        st.pyplot(plt)\n",
        "\n",
        "        # Downloadable JSON\n",
        "        result = {\"steps\": steps, \"calories\": calories, \"active_minutes\": active_minutes, \"fitness_tip\": tip}\n",
        "        st.download_button(\n",
        "            label=\"Download Insights as JSON\",\n",
        "            data=json.dumps(result, indent=4),\n",
        "            file_name=\"fitness_insights.json\",\n",
        "            mime=\"application/json\",\n",
        "        )\n",
        "\n",
        "# Tab 2: Sleep Analysis\n",
        "with tab2:\n",
        "    st.subheader(\"Sleep Analysis\")\n",
        "    st.markdown(\"Input your sleep data for personalized recommendations.\")\n",
        "\n",
        "    # Inputs\n",
        "    sleep_hours = st.number_input(\"Sleep Duration (hours):\", min_value=0, step=1)\n",
        "    disturbances = st.number_input(\"Nightly Disturbances:\", min_value=0, step=1)\n",
        "\n",
        "    # Generate insights\n",
        "    if st.button(\"Analyze Sleep\"):\n",
        "        input_text = f\"User sleeps {sleep_hours} hours and experiences {disturbances} disturbances. Provide tips for improvement.\"\n",
        "        with st.spinner(\"Analyzing sleep patterns...\"):\n",
        "            tip = text_generation_model(input_text)[0][\"generated_text\"]\n",
        "\n",
        "        st.success(f\"Sleep Tip: {tip}\")\n",
        "        avg_sleep = average_metrics[\"daily_sleep_hours\"]\n",
        "        st.write(f\"Your sleep: **{sleep_hours} hours** (Recommended: 7-9 hours).\")\n",
        "        st.info(\"Consider adjustments to meet recommended sleep if necessary.\") if sleep_hours < avg_sleep else st.success(\"Great sleep duration!\")\n",
        "\n",
        "        # Downloadable insights\n",
        "        result = {\"sleep_hours\": sleep_hours, \"disturbances\": disturbances, \"sleep_tip\": tip}\n",
        "        st.download_button(\n",
        "            label=\"Download Sleep Analysis as JSON\",\n",
        "            data=json.dumps(result, indent=4),\n",
        "            file_name=\"sleep_analysis.json\",\n",
        "            mime=\"application/json\",\n",
        "        )\n",
        "\n",
        "# Tab 3: Journaling Sentiment Analysis\n",
        "with tab3:\n",
        "    st.subheader(\"Journaling Sentiment Analysis\")\n",
        "    st.markdown(\"Write your thoughts below, and we'll analyze your emotions.\")\n",
        "\n",
        "    # Inputs\n",
        "    journal_text = st.text_area(\"Journal Entries (One per line):\", height=200)\n",
        "\n",
        "    if st.button(\"Analyze Sentiment\"):\n",
        "        if journal_text.strip():\n",
        "            entries = [line.strip() for line in journal_text.split(\"\\n\") if line.strip()]\n",
        "            sentiments = [{\"entry\": entry, \"sentiment\": sentiment_analysis_model(entry)[0][\"label\"]} for entry in entries]\n",
        "\n",
        "            # Display results\n",
        "            st.write(\"Sentiment Analysis Results:\")\n",
        "            st.table(sentiments)\n",
        "\n",
        "            # Word cloud\n",
        "            st.write(\"Word Cloud of Your Journal:\")\n",
        "            wordcloud = WordCloud(background_color=\"white\").generate(\" \".join(entries))\n",
        "            plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "            plt.axis(\"off\")\n",
        "            st.pyplot(plt)\n",
        "\n",
        "            # Downloadable results\n",
        "            st.download_button(\n",
        "                label=\"Download Sentiment Analysis as JSON\",\n",
        "                data=json.dumps(sentiments, indent=4),\n",
        "                file_name=\"sentiment_analysis.json\",\n",
        "                mime=\"application/json\",\n",
        "            )\n",
        "        else:\n",
        "            st.warning(\"Please provide valid journal entries.\")"
      ],
      "metadata": {
        "id": "86pkzEN2b84N",
        "outputId": "395e3299-3cf7-4911-aa49-08704f3d723b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "xatUVGLINPJK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run app in the background\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "s9k4UfamcMLL",
        "outputId": "05710d4c-a02c-4701-94b1-a2d79d9f3de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.197.182:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://kind-dancers-relate.loca.lt\n",
            "2024-11-28 09:29:28.708351: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-28 09:29:28.737181: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-28 09:29:28.746070: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-28 09:29:28.766331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-28 09:29:30.277597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 1.57k/1.57k [00:00<00:00, 8.85MB/s]\n",
            "pytorch_model.bin: 100% 730M/730M [00:07<00:00, 94.3MB/s]\n",
            "generation_config.json: 100% 347/347 [00:00<00:00, 1.47MB/s]\n",
            "tokenizer_config.json: 100% 1.15k/1.15k [00:00<00:00, 5.60MB/s]\n",
            "vocab.json: 100% 127k/127k [00:00<00:00, 6.77MB/s]\n",
            "merges.txt: 100% 62.9k/62.9k [00:00<00:00, 986kB/s]\n",
            "added_tokens.json: 100% 16.0/16.0 [00:00<00:00, 55.3kB/s]\n",
            "special_tokens_map.json: 100% 772/772 [00:00<00:00, 4.56MB/s]\n",
            "tokenizer.json: 100% 310k/310k [00:00<00:00, 4.55MB/s]\n",
            "config.json: 100% 629/629 [00:00<00:00, 2.48MB/s]\n",
            "model.safetensors: 100% 268M/268M [00:04<00:00, 58.8MB/s]\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 233kB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.77MB/s]\n",
            "2024-11-28 09:29:57.459 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2024-11-28 09:30:41.856 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}